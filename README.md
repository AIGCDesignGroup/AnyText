# AnyText: Multilingual Visual Text Generation And Editing

<a href='https://arxiv.org/abs/2311.03054'><img src='https://img.shields.io/badge/Paper-Arxiv-red'></a>

![sample](docs/sample.jpg "sample")

## üìåNews
[2023.12.05] - The paper is available at [here](https://arxiv.org/abs/2311.03054).

## ‚è∞Coming soon
Thank you all for your interest in AnyText! 
We are in the last process of making necessary preparations before open-sourcing. With minor adjustments to our method and dataset, we are optimizing our model to reduce the probability of generating watermark or fake text in the background. Simultaneously, we are also developing a user-friendly demo that will allow everyone to easily generate the desired images. As promised initially, all the codes, models, and datasets of AnyText will be open-sourced. Please bear with us a little longer, and thank you for your patience!

## Citation
```
@article{tuo2023anytext,
      title={AnyText: Multilingual Visual Text Generation And Editing}, 
      author={Yuxiang Tuo and Wangmeng Xiang and Jun-Yan He and Yifeng Geng and Xuansong Xie},
      year={2023},
      eprint={2311.03054},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}
```

